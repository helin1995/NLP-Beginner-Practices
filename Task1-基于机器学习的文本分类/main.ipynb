{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bde0cb95-e6b1-4ef3-af8f-a6fceedfef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from softmax_regression import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6903603f-ff18-4b42-add3-f9702bd174f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./dataset'):\n",
    "    current_path = os.getcwd()           # 获得当前路径\n",
    "    os.mkdir(current_path + '/dataset')  # 添加dataset路径\n",
    "    path = './sentiment-analysis-on-movie-reviews/train.tsv'  # 原始数据所在路径\n",
    "    generate_dataset(path)  # 生成数据集：训练集、开发集和测试集（train.txt、dev.txt和test.txt）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1b013ad-e386-452a-b22a-c1f15e274e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行数据清洗！\n",
      "数据清洗完成！\n",
      "开始生成词典！\n",
      "已生成好词典！\n"
     ]
    }
   ],
   "source": [
    "train_path = './dataset/train.txt'\n",
    "vocab, data = build_vocab(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97930211-e351-432f-88f2-482fee7fd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_extraction(vocab, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d462380-68d2-4cde-83a5-868540359c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行数据清洗！\n",
      "数据清洗完成！\n"
     ]
    }
   ],
   "source": [
    "dev_path = './dataset/dev.txt'\n",
    "dev_data = data_clean(dev_path)\n",
    "dev_feature = feature_extraction(vocab, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5198163-11df-451e-9348-1146a460b74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dev_feature[-1][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0cf8ae6a-e711-4018-be1a-44fd51e58205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3b4aa883-5c0f-469d-b552-970ae5c3157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, class_nums):\n",
    "    '''\n",
    "    将标签改为one-hot编码\n",
    "    '''\n",
    "    y_new = np.zeros((class_nums, len(y)))\n",
    "    for idx, val in enumerate(y):\n",
    "        y_new[int(val)][idx] = 1\n",
    "    return y_new    \n",
    "    \n",
    "def cross_entropy_loss(y_, y):\n",
    "    '''\n",
    "    交叉熵损失函数\n",
    "    y_：模型预测值\n",
    "    y：真实标签值\n",
    "    '''\n",
    "    N = y.shape[1]  # batch_size\n",
    "    loss = 0.\n",
    "    for i in range(N):\n",
    "        for j in range(5):\n",
    "            loss += -y[j][i] * np.log(y_[j][i])\n",
    "    # loss = loss / N\n",
    "    return (loss / N, loss)\n",
    "\n",
    "def compute_accuracy(y_, y):\n",
    "    N = len(y)\n",
    "    correct_nums = 0\n",
    "    for i in range(N):\n",
    "        if y_[i] == y[i]:\n",
    "            correct_nums += 1\n",
    "    return (correct_nums / N, correct_nums)\n",
    "\n",
    "def update_parameter(model, x, y, y_):\n",
    "    lr = 1e-2\n",
    "    N = x.shape[0]\n",
    "    sigma = np.zeros((model.Weight.shape[0], model.Weight.shape[1]))\n",
    "    for i in range(N):\n",
    "        sigma += np.matmul((y.T[i]-y_.T[i]).reshape(-1, 1), x[i].reshape(1, -1))\n",
    "    model.Weight = model.Weight + lr * sigma / N\n",
    "    \n",
    "def evaluate(model, dev):\n",
    "    N = len(dev)\n",
    "    batch_correct_nums = 0.\n",
    "    batch_loss = 0.\n",
    "    for x, y in data_iter(dev):\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        one = np.ones((x.shape[0], 1))\n",
    "        x = np.concatenate((x, one), axis=1)          # 将x变为增广矩阵\n",
    "        y_hat = model.forward(x)                      # 使用模型得到每个样本的标签（类别）的概率分布\n",
    "        y_pred_label = np.argmax(y_hat, axis=0)       # 使用argmax得到模型预测的结果\n",
    "        _, correct_nums = compute_accuracy(y_pred_label, y)  # 计算mini-batch的准确率\n",
    "        batch_correct_nums += correct_nums\n",
    "        y = one_hot_encode(y, 5)                      # 将样本标签转化为one-hot向量，用于使用交叉熵损失函数计算mini-batch的loss\n",
    "        _, loss = cross_entropy_loss(y_hat, y)        # 计算mini-batch loss\n",
    "        batch_loss += loss\n",
    "    return (batch_correct_nums / N, batch_loss / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9faa50a9-d69d-4ba4-8cbe-c63a93e17cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/20]\n",
      "train loss: 2.6544\t train accuracy: 0.2969\t dev accuracy: 0.3070\t dev loss: 2.5619\t*\n",
      "train loss: 2.2801\t train accuracy: 0.3594\t dev accuracy: 0.3341\t dev loss: 2.4739\t*\n",
      "train loss: 2.7340\t train accuracy: 0.2656\t dev accuracy: 0.3517\t dev loss: 2.4110\t*\n",
      "train loss: 2.6176\t train accuracy: 0.3359\t dev accuracy: 0.3645\t dev loss: 2.3658\t*\n",
      "train loss: 2.3771\t train accuracy: 0.3594\t dev accuracy: 0.3745\t dev loss: 2.3315\t*\n",
      "epoch: [2/20]\n",
      "train loss: 2.6977\t train accuracy: 0.3672\t dev accuracy: 0.3829\t dev loss: 2.3049\t*\n",
      "train loss: 2.2836\t train accuracy: 0.3516\t dev accuracy: 0.3902\t dev loss: 2.2833\t*\n",
      "train loss: 2.1025\t train accuracy: 0.4297\t dev accuracy: 0.3946\t dev loss: 2.2660\t*\n",
      "train loss: 1.9921\t train accuracy: 0.4141\t dev accuracy: 0.3977\t dev loss: 2.2514\t*\n",
      "train loss: 2.0614\t train accuracy: 0.3828\t dev accuracy: 0.4007\t dev loss: 2.2393\t*\n",
      "train loss: 2.1046\t train accuracy: 0.3750\t dev accuracy: 0.4030\t dev loss: 2.2292\t*\n",
      "epoch: [3/20]\n",
      "train loss: 2.3956\t train accuracy: 0.3984\t dev accuracy: 0.4041\t dev loss: 2.2205\t*\n",
      "train loss: 2.1393\t train accuracy: 0.3984\t dev accuracy: 0.4053\t dev loss: 2.2128\t*\n",
      "train loss: 2.2986\t train accuracy: 0.4141\t dev accuracy: 0.4063\t dev loss: 2.2063\t*\n",
      "train loss: 1.9856\t train accuracy: 0.3828\t dev accuracy: 0.4073\t dev loss: 2.2003\t*\n",
      "train loss: 2.1720\t train accuracy: 0.4375\t dev accuracy: 0.4083\t dev loss: 2.1950\t*\n",
      "train loss: 2.0835\t train accuracy: 0.3984\t dev accuracy: 0.4086\t dev loss: 2.1904\t*\n",
      "epoch: [4/20]\n",
      "train loss: 1.8366\t train accuracy: 0.4062\t dev accuracy: 0.4094\t dev loss: 2.1862\t*\n",
      "train loss: 2.2803\t train accuracy: 0.4297\t dev accuracy: 0.4099\t dev loss: 2.1823\t*\n",
      "train loss: 2.0138\t train accuracy: 0.4531\t dev accuracy: 0.4102\t dev loss: 2.1789\t*\n",
      "train loss: 2.1096\t train accuracy: 0.3516\t dev accuracy: 0.4105\t dev loss: 2.1756\t*\n",
      "train loss: 2.7263\t train accuracy: 0.3438\t dev accuracy: 0.4108\t dev loss: 2.1725\t*\n",
      "train loss: 2.2126\t train accuracy: 0.3750\t dev accuracy: 0.4111\t dev loss: 2.1698\t*\n",
      "epoch: [5/20]\n",
      "train loss: 2.0757\t train accuracy: 0.3828\t dev accuracy: 0.4117\t dev loss: 2.1672\t*\n",
      "train loss: 1.8563\t train accuracy: 0.4609\t dev accuracy: 0.4118\t dev loss: 2.1647\t*\n",
      "train loss: 2.3918\t train accuracy: 0.3906\t dev accuracy: 0.4125\t dev loss: 2.1624\t*\n",
      "train loss: 2.1956\t train accuracy: 0.4297\t dev accuracy: 0.4130\t dev loss: 2.1602\t*\n",
      "train loss: 2.0505\t train accuracy: 0.4297\t dev accuracy: 0.4135\t dev loss: 2.1580\t*\n",
      "train loss: 2.3287\t train accuracy: 0.3906\t dev accuracy: 0.4134\t dev loss: 2.1561\t*\n",
      "epoch: [6/20]\n",
      "train loss: 2.2661\t train accuracy: 0.4062\t dev accuracy: 0.4134\t dev loss: 2.1541\t*\n",
      "train loss: 2.5161\t train accuracy: 0.3594\t dev accuracy: 0.4132\t dev loss: 2.1522\t*\n",
      "train loss: 2.1095\t train accuracy: 0.4219\t dev accuracy: 0.4135\t dev loss: 2.1505\t*\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-213f342de21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# end_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# print('train loss: %.4f\\ttrain accuracy: %.4f' % (loss, accuracy))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mdev_accu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_dev_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mbest_dev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-3f662fbb2a25>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dev)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python37-tf/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = 1\n",
    "best_dev_loss = float('inf')\n",
    "flag = False\n",
    "last_improve = 0\n",
    "for epoch in range(20):\n",
    "    print('epoch: [%d/%d]' % (epoch+1, 20))\n",
    "    for x, y in data_iter(feature):\n",
    "        # start_time = time.time()\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        one = np.ones((x.shape[0], 1))\n",
    "        x = np.concatenate((x, one), axis=1)             # 将x变为增广矩阵\n",
    "        y_hat = model.forward(x)                         # 使用模型得到每个样本的标签（类别）的概率分布\n",
    "        y_pred_label = np.argmax(y_hat, axis=0)          # 使用argmax得到模型预测的结果\n",
    "        accuracy, _ = compute_accuracy(y_pred_label, y)  # 计算mini-batch的准确率\n",
    "        y = one_hot_encode(y, 5)                       # 将样本标签转化为one-hot向量，用于使用交叉熵损失函数计算mini-batch的loss\n",
    "        loss, _ = cross_entropy_loss(y_hat, y)         # 计算mini-batch loss\n",
    "        update_parameter(model, x, y, y_hat)           # 更新参数\n",
    "        if total_batch % 100 == 0:\n",
    "            # end_time = time.time()\n",
    "            # print('train loss: %.4f\\ttrain accuracy: %.4f' % (loss, accuracy))\n",
    "            dev_accu, dev_loss = evaluate(model, dev_feature)\n",
    "            if dev_loss < best_dev_loss:\n",
    "                best_dev_loss = dev_loss\n",
    "                improve =  '*'\n",
    "                last_improve = total_batch\n",
    "                # save model\n",
    "                np.save('model/weights', model.Weight, allow_pickle=True, fix_imports=True)\n",
    "            else:\n",
    "                improve = ''\n",
    "            print('train loss: {:.4f}\\t train accuracy: {:.4f}\\t dev accuracy: {:.4f}\\t dev loss: {:.4f}\\t{}'.format(loss, accuracy, dev_accu, dev_loss, improve))\n",
    "        if total_batch - last_improve > 300:\n",
    "            flag = True\n",
    "            break\n",
    "        total_batch += 1\n",
    "    if flag:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37-tf] *",
   "language": "python",
   "name": "conda-env-python37-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
